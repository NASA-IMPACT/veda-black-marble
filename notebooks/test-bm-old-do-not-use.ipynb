{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92315d6b-ec48-46ec-8a56-84b3e60d2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import gdal\n",
    "except ImportError:\n",
    "    from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43ac5a-ec24-4270-9f91-d4a57fbc9c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install 'gdal==3.6.2'\n",
    "! pip3 install --no-cache-dir --force-reinstall 'GDAL[numpy]==3.6.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581a2d2-7c96-4193-a6ae-8241f1ab03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install utm\n",
    "! pip3 install scikit-image\n",
    "! pip3 install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58404ecb-f705-44d8-a2c0-ddd386192af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install shapely\n",
    "! pip3 install boto3\n",
    "! pip3 install rasterio\n",
    "! pip3 install fiona\n",
    "! pip3 install osmnx\n",
    "! pip3 install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b3c54-79c0-4367-8069-10806fcfd098",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key = ''\n",
    "aws_secret_key = ''\n",
    "# Get a token from https://urs.earthdata.nasa.gov/\n",
    "earthdata_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57c37c-7920-4414-a844-ac34b3157f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from osgeo import ogr\n",
    "import shapely.geometry\n",
    "import shapely.wkt\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import utm\n",
    "from numpy import inf\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import fiona\n",
    "import fiona.transform\n",
    "import requests\n",
    "import osmnx as ox\n",
    "import os.path\n",
    "from pyproj import Proj\n",
    "import json\n",
    "import utm\n",
    "from geopy.distance import geodesic\n",
    "from rasterio.io import MemoryFile\n",
    "from rio_cogeo.profiles import cog_profiles\n",
    "from rio_cogeo.cogeo import cog_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c3006-9af1-46c7-b9a7-ff9bc4cc225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_geo(f, band):\n",
    "    ds = gdal.Open(f, gdal.GA_ReadOnly)\n",
    "    cols = ds.RasterXSize\n",
    "    rows = ds.RasterYSize\n",
    "    img = ds.GetRasterBand(band).ReadAsArray(0,0,cols,rows)\n",
    "    in_geo = ds.GetGeoTransform()\n",
    "    projref = ds.GetProjectionRef()\n",
    "    ds = None\n",
    "    return img, in_geo, projref\n",
    "\n",
    "def save_image(f,in_geo,projref,type,out):\n",
    "    #create New Raster\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    if driver == None:\n",
    "        print (\"Failed to find the gdal driver\")\n",
    "        exit()\n",
    "    newRaster = driver.Create(out, f.shape[1], f.shape[0], 1, type)\n",
    "    newRaster.SetProjection(projref)\n",
    "    newRaster.SetGeoTransform(in_geo)\n",
    "    outBand = newRaster.GetRasterBand(1)\n",
    "    outBand.SetNoDataValue(0)\n",
    "    outBand.WriteArray(f, 0, 0)\n",
    "    driver = None\n",
    "    outBand = None\n",
    "    newRaster = None\n",
    "\n",
    "def scale_image(inputarry, min_value, max_value):\n",
    "    inputarry = np.where(inputarry > max_value, max_value,inputarry)\n",
    "    inputarry = np.where(inputarry < min_value, min_value,inputarry)\n",
    "    new_arr = ((inputarry - inputarry.min()) * (1/(inputarry.max() - inputarry.min()) * 255)).astype('uint8')\n",
    "    return new_arr\n",
    "\n",
    "def save_geotiff_rgb(filename, r, g, b, projref, in_geo):\n",
    "  # Write a GeoTIFF\n",
    "  format = 'GTiff'\n",
    "  rows, cols = np.shape(r)\n",
    "  driver = gdal.GetDriverByName(format)\n",
    "  out_ds = driver.Create(filename, cols, rows, 3, gdal.GDT_Byte)\n",
    "  out_ds.SetProjection(projref)\n",
    "  out_ds.SetGeoTransform(in_geo)\n",
    "  out_ds.GetRasterBand(1).WriteArray(r)\n",
    "  out_ds.GetRasterBand(2).WriteArray(g)\n",
    "  out_ds.GetRasterBand(3).WriteArray(b)\n",
    "  out_ds = None\n",
    "\n",
    "def save_geotiff_single(filename, band_data, projref, in_geo):\n",
    "  # Write a GeoTIFF\n",
    "  format = 'GTiff'\n",
    "  rows, cols = np.shape(band_data)\n",
    "  driver = gdal.GetDriverByName(format)\n",
    "  out_ds = driver.Create(filename, cols, rows, 1, gdal.GDT_UInt16)\n",
    "  out_ds.SetProjection(projref)\n",
    "  out_ds.SetGeoTransform(in_geo)\n",
    "  out_ds.GetRasterBand(1).WriteArray(band_data)\n",
    "  out_ds = None\n",
    "\n",
    "# https://blackmarble.gsfc.nasa.gov/tools/OpenHDF5.py\n",
    "def convert_VNP46A2_HDF2TIFF(hf5File, outputFile):\n",
    "    hdflayer = gdal.Open(hf5File, gdal.GA_ReadOnly)\n",
    "    subhdflayer = hdflayer.GetSubDatasets()[2][0]\n",
    "    rlayer = gdal.Open(subhdflayer, gdal.GA_ReadOnly)\n",
    "    rasterFilePre = hf5File[:-3]\n",
    "    HorizontalTileNumber = int(rlayer.GetMetadata_Dict()[\"HorizontalTileNumber\"])\n",
    "    VerticalTileNumber = int(rlayer.GetMetadata_Dict()[\"VerticalTileNumber\"])\n",
    "    WestBoundCoord = (10*HorizontalTileNumber) - 180\n",
    "    NorthBoundCoord = 90-(10*VerticalTileNumber)\n",
    "    EastBoundCoord = WestBoundCoord + 10\n",
    "    SouthBoundCoord = NorthBoundCoord - 10\n",
    "    EPSG = \"-a_srs EPSG:4326\" #WGS84\n",
    "    translateOptionText = EPSG+\" -a_ullr \" + str(WestBoundCoord) + \" \" + str(NorthBoundCoord) + \" \" + str(EastBoundCoord) + \" \" + str(SouthBoundCoord)\n",
    "    translateoptions = gdal.TranslateOptions(gdal.ParseCommandLine(translateOptionText))\n",
    "    gdal.Translate(outputFile,rlayer, options=translateoptions)\n",
    "\n",
    "def subset_raster_normal(inputRaster, outputRaster, minX, maxY, maxX, minY, scale):\n",
    "  ds = gdal.Open(inputRaster)\n",
    "  #extended BBox\n",
    "  top1 = maxY\n",
    "  left1 = minX\n",
    "  bottom1 = minY\n",
    "  right1 = maxX\n",
    "  ds = gdal.Translate('new1.tif', inputRaster, projWin = [left1, top1, right1, bottom1], resampleAlg='bilinear')\n",
    "  ds = None\n",
    "  ds = gdal.Open('new1.tif')\n",
    "  ds = gdal.Warp('new2.tif', ds, xRes=scale, yRes=scale, resampleAlg='bilinear')\n",
    "  ds = None\n",
    "  ds = gdal.Open('new2.tif')\n",
    "  ds = gdal.Translate(outputRaster, ds, projWin = [minX, maxY, maxX, minY], resampleAlg='bilinear')\n",
    "  ds = None\n",
    "  os.remove('new1.tif')\n",
    "  os.remove('new2.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6949b6-edf2-4a4a-baa9-36f47b242bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/robintw/LatLongToWRS/blob/master/get_wrs.py\n",
    "\n",
    "class LandsatUtil:\n",
    "    \"\"\"Class which performs conversion between latitude/longitude co-ordinates\n",
    "    and Landsat WRS-2 paths and rows.\n",
    "    Requirements:\n",
    "    * OGR (in the GDAL suite)\n",
    "    * Shapely\n",
    "    * Landsat WRS-2 Path/Row Shapefiles - download from USGS site\n",
    "     (http://landsat.usgs.gov/tools_wrs-2_shapefile.php), you want wrs2_descending.zip\n",
    "    Usage:\n",
    "    1. Create an instance of the class:\n",
    "        conv = ConvertToWRS()\n",
    "    (This will take a while to run, as it loads\n",
    "    the shapefiles in to memory)\n",
    "    2. Use the get_wrs method to do a conversion:\n",
    "        print conv.get_wrs(50.14, -1.43)\n",
    "    For example:\n",
    "        >>> conv = ConvertToWRS()\n",
    "        >>> conv.get_wrs(50.14, -1.7)\n",
    "        [{'path': 202, 'row': 25}]\n",
    "        >>> conv.get_wrs(50.14, -1.43)\n",
    "        [{'path': 201, 'row': 25}, {'path': 202, 'row': 25}]\n",
    "    \"\"\"\n",
    "    def __init__(self, shapefile=\"./WRS2_descending.shp\"):\n",
    "        \"\"\"Create a new instance of the ConvertToWRS class,\n",
    "        and load the shapefiles into memory.\n",
    "        If it can't find the shapefile then specify the path\n",
    "        using the shapefile keyword - but it should work if the\n",
    "        shapefile is in the same directory.\n",
    "        \"\"\"\n",
    "        # Open the shapefile\n",
    "        self.shapefile = ogr.Open(shapefile)\n",
    "        # Get the only layer within it\n",
    "        self.layer = self.shapefile.GetLayer(0)\n",
    "        self.polygons = []\n",
    "        # For each feature in the layer\n",
    "        for i in range(self.layer.GetFeatureCount()):\n",
    "            # Get the feature, and its path and row attributes\n",
    "            feature = self.layer.GetFeature(i)\n",
    "            path = feature['PATH']\n",
    "            row = feature['ROW']\n",
    "            # Get the geometry into a Shapely-compatible\n",
    "            # format by converting to Well-known Text (Wkt)\n",
    "            # and importing that into shapely\n",
    "            geom = feature.GetGeometryRef()\n",
    "            shape = shapely.wkt.loads(geom.ExportToWkt())\n",
    "            # Store the shape and the path/row values\n",
    "            # in a list so we can search it easily later\n",
    "            self.polygons.append((shape, path, row))\n",
    "\n",
    "\n",
    "    def get_wrs(self, lat, lon):\n",
    "        \"\"\"Get the Landsat WRS-2 path and row for the given\n",
    "        latitude and longitude co-ordinates.\n",
    "        Returns a list of dicts, as some points will be in the\n",
    "        overlap between two (or more) landsat scene areas:\n",
    "        [{path: 202, row: 26}, {path:186, row=7}]\n",
    "        \"\"\"\n",
    "        # Create a point with the given latitude\n",
    "        # and longitude (NB: the arguments are lon, lat\n",
    "        # not lat, lon)\n",
    "        pt = shapely.geometry.Point(lon, lat)\n",
    "        res = []\n",
    "        # Iterate through every polgon\n",
    "        for poly in self.polygons:\n",
    "            # If the point is within the polygon then\n",
    "            # append the current path/row to the results\n",
    "            # list\n",
    "            if pt.within(poly[0]):\n",
    "                res.append({'path': poly[1], 'row': poly[2]})\n",
    "        # Return the results list to the user\n",
    "        return res\n",
    "\n",
    "    def filter_landsat_data_dir(self, year, month, day, path, row):\n",
    "\n",
    "        year = str(year)\n",
    "        month = str(month).zfill(2)\n",
    "        day = str(day).zfill(2)\n",
    "        session = boto3.Session( aws_access_key_id= aws_access_key, aws_secret_access_key= aws_secret_key)\n",
    "        s3 = session.client('s3')\n",
    "        directories = s3.list_objects_v2(\n",
    "            Bucket='usgs-landsat',\n",
    "            Prefix='collection02/level-2/standard/oli-tirs/' + str(year) + '/' + path + '/' + row + '/',\n",
    "            RequestPayer='requester',\n",
    "            Delimiter='/'\n",
    "        )['CommonPrefixes']\n",
    "        selected_start_date = None\n",
    "        selected_end_date = None\n",
    "        selected_prefix = None\n",
    "        for entry in directories:\n",
    "            date_range = entry['Prefix'].split('/')[-2].split('_')[3:5]\n",
    "            target_date = datetime.strptime(year + month + day, '%Y%m%d')\n",
    "            start_date = datetime.strptime(date_range[0], '%Y%m%d')\n",
    "            end_date = datetime.strptime(date_range[1], '%Y%m%d')\n",
    "            if target_date >= start_date and target_date <= end_date:\n",
    "                if selected_start_date:\n",
    "                    if selected_start_date < start_date and selected_end_date > end_date:\n",
    "                        selected_prefix = entry['Prefix']\n",
    "                        selected_start_date = start_date\n",
    "                        selected_end_date = end_date\n",
    "                else:    \n",
    "                    selected_prefix = entry['Prefix']\n",
    "                    selected_start_date = start_date\n",
    "                    selected_end_date = end_date\n",
    "        return selected_prefix\n",
    "    \n",
    "    def download_landsat_band(self, dir, band, output_path):\n",
    "        if str(band) == 'QA_PIXEL':\n",
    "            band_file = dir + dir.split('/')[-2] + \"_QA_PIXEL.TIF\"\n",
    "            print(\"Downloading QA_PIXEL \", band_file)\n",
    "        elif str(band) == 'QA_RADSAT':\n",
    "            band_file = dir + dir.split('/')[-2] + \"_QA_RADSAT.TIF\"\n",
    "            print(\"Downloading QA_RADSAT \", band_file)\n",
    "        elif str(band) == 'QA_AEROSOL':\n",
    "            band_file = dir + dir.split('/')[-2] + \"_SR_QA_AEROSOL.TIF\"\n",
    "            print(\"Downloading QA_AEROSOL \", band_file)\n",
    "        else:\n",
    "            band_file = dir + dir.split('/')[-2] + \"_SR_B\" + str(band) + \".TIF\"\n",
    "            print(\"Downloading Band  \", band_file)\n",
    "        session = boto3.Session( aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key)\n",
    "        s3 = session.client('s3')\n",
    "        files = s3.list_objects_v2(\n",
    "            Bucket='usgs-landsat',\n",
    "            Prefix=band_file,\n",
    "            RequestPayer='requester',\n",
    "        )['Contents']\n",
    "        print(\"Downloading file \" + band_file + \" to path \"  + output_path)\n",
    "        s3.download_file('usgs-landsat', band_file, output_path, ExtraArgs = {\"RequestPayer\": \"requester\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5723718-bc53-40b7-b094-d85c28819b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSMUtil:\n",
    "    def create_road_raster_flattened(self, lat1, long1, lat2, long2, raster_value = 5,\n",
    "                           reference_raster = \"outputs/ntl.tif\",\n",
    "                           output_path= \"outputs/osm.tif\", path_thickness = 0.00005):\n",
    "        with rasterio.open(reference_raster) as f:\n",
    "                    height = f.height\n",
    "                    width = f.width\n",
    "                    crs = f.crs.to_string()\n",
    "                    transform = f.transform\n",
    "                    crs = f.crs.to_string()\n",
    "                    profile = f.profile\n",
    "        G = ox.graph_from_bbox(max(lat1, lat2), \n",
    "                               min(lat1, lat2), \n",
    "                               max(long1, long2),\n",
    "                               min(long1, long2), \n",
    "                               retain_all=True,\n",
    "                               network_type=\"all\")\n",
    "        ox.save_graph_shapefile(G, \"roads\")\n",
    "        roads_shapefile_fn =  \"roads/edges.shp\"\n",
    "        road_shapes = []\n",
    "        with fiona.open(roads_shapefile_fn) as f:\n",
    "            for row in f:\n",
    "                geom = row[\"geometry\"]\n",
    "                #geom = fiona.transform.transform_geom(\"epsg:4326\", crs, geom)\n",
    "                shape = shapely.geometry.shape(geom)\n",
    "                shape = shape.buffer(path_thickness) # buffer the linestrings in angles\n",
    "                road_shapes.append(shapely.geometry.mapping(shape))\n",
    "        mask = rasterio.features.rasterize(road_shapes, \n",
    "                                           out_shape=(height, width), \n",
    "                                           fill=0, \n",
    "                                           transform=transform, \n",
    "                                           all_touched=False, \n",
    "                                           default_value=5, \n",
    "                                           dtype=np.uint8)\n",
    "        profile[\"count\"] = 1\n",
    "        profile[\"dtype\"] = \"uint8\"\n",
    "        #profile[\"nodata\"] = 0\n",
    "        with rasterio.open(output_path, \"w\", **profile) as f:\n",
    "            f.write(mask, 1)\n",
    "    def create_road_raster(self, lat1, long1, lat2, long2, raster_value = 5,\n",
    "                           reference_raster = \"outputs/adjusted_ntl.tif\",\n",
    "                           output_path= \"outputs/osm.tif\", path_thickness = 0.00005):\n",
    "        with rasterio.open(reference_raster) as f:\n",
    "                    height = f.height\n",
    "                    width = f.width\n",
    "                    crs = f.crs.to_string()\n",
    "                    transform = f.transform\n",
    "                    crs = f.crs.to_string()\n",
    "                    profile = f.profile\n",
    "        base = np.zeros((height, width))\n",
    "        filters = ['[\"highway\"~\"primary_link|primary|secondary|secondary_link|tertiary|tertiary_link\"]',\n",
    "                   '[\"highway\"~\"motorway|motorway_link\"]',\n",
    "                   '[\"highway\"~\"residential\"]',\n",
    "                   '[\"highway\"~\"trunk|trunk_link\"]',\n",
    "                   '[\"highway\"~\"service|unclassified|road|busway\"]'\n",
    "                  ]\n",
    "        for idx, filter in enumerate(filters):\n",
    "            try:\n",
    "                G = ox.graph_from_bbox(max(lat1, lat2), \n",
    "                                       min(lat1, lat2), \n",
    "                                       max(long1, long2),\n",
    "                                       min(long1, long2), \n",
    "                                       retain_all=True,\n",
    "                                       network_type=\"all\", \n",
    "                                       custom_filter=filter)\n",
    "                ox.save_graph_shapefile(G, \"roads\")\n",
    "                roads_shapefile_fn =  \"roads/edges.shp\"\n",
    "                road_shapes = []\n",
    "                with fiona.open(roads_shapefile_fn) as f:\n",
    "                    for row in f:\n",
    "                        geom = row[\"geometry\"]\n",
    "                        #geom = fiona.transform.transform_geom(\"epsg:4326\", crs, geom)\n",
    "                        shape = shapely.geometry.shape(geom)\n",
    "                        shape = shape.buffer(path_thickness) # buffer the linestrings in angles\n",
    "                        road_shapes.append(shapely.geometry.mapping(shape))\n",
    "                mask = rasterio.features.rasterize(road_shapes, \n",
    "                                                   out_shape=(height, width), \n",
    "                                                   fill=0, \n",
    "                                                   transform=transform, \n",
    "                                                   all_touched=False, \n",
    "                                                   default_value=idx + 1, \n",
    "                                                   dtype=np.uint8)\n",
    "                for row in range(height):\n",
    "                    for col in range(width):\n",
    "                        if mask[row][col] > base[row][col]:\n",
    "                            base[row][col] = mask[row][col]\n",
    "            except:\n",
    "                print(\"No data for filter \" + filter)\n",
    "        profile[\"count\"] = 1\n",
    "        profile[\"dtype\"] = \"uint8\"\n",
    "        #profile[\"nodata\"] = 0\n",
    "        with rasterio.open(output_path, \"w\", **profile) as f:\n",
    "            f.write(base, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af55eca5-f38d-4ce9-b94b-802e92086443",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNP46A2Util:\n",
    "    def coordinates_to_tile_id(self, lat, longi):\n",
    "        lat = -lat + 90.0\n",
    "        longi = longi + 180.0\n",
    "        tile_v = (lat / 180) * 18\n",
    "        tile_h = (longi / 360) * 36\n",
    "        return (int(tile_v), int(tile_h))\n",
    "    def download_h5(self, earthdata_token, year, month, day, vertical, horizontal, download_file = \"VNP46A2.h5\"):\n",
    "        target_coordinate = \"h\" + str(horizontal).zfill(2) + \"v\" + str(vertical).zfill(2)\n",
    "        dt_year = date(year, month, day).timetuple().tm_yday \n",
    "        #dt_year = 308\n",
    "        json_api = \"https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/details/allData/5000/VNP46A2/\" + str(year) + \"/\" + str(dt_year)\n",
    "        response = requests.get(json_api)    \n",
    "        dict = response.json()\n",
    "        download_link  = None\n",
    "        for elem in dict['content']:\n",
    "            coordinate = elem['name'].split('.')[2]\n",
    "            if coordinate == target_coordinate:\n",
    "                print(elem)\n",
    "                download_link = elem['downloadsLink']\n",
    "                break\n",
    "        if not download_link:\n",
    "            print(\"Could not find a VNP46A2 product for coordinate \", target_coordinate)\n",
    "        else:\n",
    "            print(\"Downloading \", download_link)\n",
    "            headers = {\n",
    "                'Authorization': f'Bearer {earthdata_token}'\n",
    "            }\n",
    "            response = requests.get(download_link, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                with open(download_file, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print('File downloaded successfully')\n",
    "            else:\n",
    "                print('Failed to download file. Status code:', response.status_code)\n",
    "    def convert_VNP46A2_HDF2TIFF(self, hf5File, outputFile, layer = 0):\n",
    "        hdflayer = gdal.Open(hf5File, gdal.GA_ReadOnly)\n",
    "        print(hdflayer.GetSubDatasets()[layer])\n",
    "        subhdflayer = hdflayer.GetSubDatasets()[layer][0]\n",
    "        rlayer = gdal.Open(subhdflayer, gdal.GA_ReadOnly)\n",
    "        rasterFilePre = hf5File[:-3]\n",
    "        HorizontalTileNumber = int(rlayer.GetMetadata_Dict()[\"HorizontalTileNumber\"])\n",
    "        VerticalTileNumber = int(rlayer.GetMetadata_Dict()[\"VerticalTileNumber\"])\n",
    "        WestBoundCoord = (10*HorizontalTileNumber) - 180\n",
    "        NorthBoundCoord = 90-(10*VerticalTileNumber)\n",
    "        EastBoundCoord = WestBoundCoord + 10\n",
    "        SouthBoundCoord = NorthBoundCoord - 10\n",
    "        EPSG = \"-a_srs EPSG:4326\" #WGS84\n",
    "        translateOptionText = EPSG+\" -a_ullr \" + str(WestBoundCoord) + \" \" + str(NorthBoundCoord) + \" \" + str(EastBoundCoord) + \" \" + str(SouthBoundCoord)\n",
    "        translateoptions = gdal.TranslateOptions(gdal.ParseCommandLine(translateOptionText))\n",
    "        gdal.Translate(outputFile,rlayer, options=translateoptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a117cc2-6476-4c69-b182-15ea02f63d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_coord():\n",
    "    return 33.034682, 21.279194, 32.465949, 22.919832\n",
    "\n",
    "\n",
    "def get_peurto_coord():\n",
    "    return 18.518435, -67.244568, 17.918391, -65.788879\n",
    "\n",
    "def get_fort_myers():\n",
    "    return 26.718905, -82.103920, 26.520302, -81.833752\n",
    "\n",
    "def turkey():\n",
    "    return 38.256313, 35.385847, 36.448697, 36.448697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5e303-7f7b-44a2-b774-9ef22930d105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28a709-020c-45f6-b252-58554b042d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiles_for_band(band, year, month, day, lat1, long1, lat2, long2, ignore_missing = False):\n",
    "    landsat = LandsatUtil(shapefile = \"./WRS2_descending_0/WRS2_descending.shp\")\n",
    "    wrs_res1 = landsat.get_wrs(lat1, long1)\n",
    "    path1 = wrs_res1[0]['path']\n",
    "    row1 = wrs_res1[0]['row']\n",
    "    wrs_res2 = landsat.get_wrs(lat2, long2)\n",
    "    path2 = wrs_res2[0]['path']\n",
    "    row2 = wrs_res2[0]['row']\n",
    "    downloaded_files = []\n",
    "    pixel_files = []\n",
    "    radsat_files = []\n",
    "    aerosol_files = []\n",
    "    for p in range(min(path1, path2), max(path1, path1) + 1 ):\n",
    "        for r in range(min(row1, row2), max(row1, row2) + 1):\n",
    "            print(\"Downloading for band \", band, \" Date \", year, \"-\", month, \"-\", day, \" Path \",  p, \" Row \", r)\n",
    "            dir = landsat.filter_landsat_data_dir(year, month, day, str(p).zfill(3), str(r).zfill(3))\n",
    "            if not dir and ignore_missing:\n",
    "                print(\"No data. Ignoring\")\n",
    "                return []\n",
    "            print(\"Data Directory \", dir)\n",
    "            local_path = \"outputs/temp/\" + dir.split('/')[-2] + \"_SR_B\" + str(band) + \".TIF\"\n",
    "            if not os.path.exists(local_path):\n",
    "                landsat.download_landsat_band(dir, band, local_path)\n",
    "            downloaded_files.append(local_path)\n",
    "            local_path = \"outputs/temp/\" + dir.split('/')[-2] + \"QA_PIXEL.TIF\"\n",
    "            if not os.path.exists(local_path):\n",
    "                landsat.download_landsat_band(dir, \"QA_PIXEL\", local_path)\n",
    "            pixel_files.append(local_path)\n",
    "            local_path = \"outputs/temp/\" + dir.split('/')[-2] + \"QA_RADSAT.TIF\"\n",
    "            if not os.path.exists(local_path):\n",
    "                landsat.download_landsat_band(dir, \"QA_RADSAT\", local_path)\n",
    "            radsat_files.append(local_path)\n",
    "            local_path = \"outputs/temp/\" + dir.split('/')[-2] + \"QA_AEROSOL.TIF\"\n",
    "            if not os.path.exists(local_path):\n",
    "                landsat.download_landsat_band(dir, \"QA_AEROSOL\", local_path)\n",
    "            aerosol_files.append(local_path)\n",
    "    return downloaded_files, pixel_files, radsat_files, aerosol_files\n",
    "\n",
    "def download_tiles_for_band_with_composites(band, year, month, day, lat1, long1, lat2, long2, composite_history_months = 12):\n",
    "    tiles = []\n",
    "    tiles.append(download_tiles_for_band(band, year, month, day, lat1, long1, lat2, long2))\n",
    "    # Download Composites\n",
    "    for comp in range(composite_history_months):\n",
    "        if month <= comp:\n",
    "            t = download_tiles_for_band(band, year - 1, 12 - comp + month, 1, lat1, long1, lat2, long2,ignore_missing = True)\n",
    "        else:\n",
    "            t = download_tiles_for_band(band, year, month - comp, 1, lat1, long1, lat2, long2, ignore_missing = True)\n",
    "        if t:\n",
    "          tiles.append(t)  \n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59264092-8e00-490a-804e-82a402e1ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wkt_to_json(wkt_string):\n",
    "    # Create a Projection object from the WKT string\n",
    "    proj = Proj(wkt_string)\n",
    "    # Convert the WKT string to a dictionary representation\n",
    "    json_dict = proj.crs.to_json_dict()\n",
    "    return json_dict\n",
    "\n",
    "def convert_to_wgs84(input, output, long1, lat1, long2, lat2):\n",
    "    ds = gdal.Open(input)\n",
    "    srs_wkt = ds.GetProjection()\n",
    "    json_data = wkt_to_json(srs_wkt)\n",
    "    src_srs = json_data['id']['code']\n",
    "    #ds = gdal.Warp(output, ds, \n",
    "    #               resampleAlg='bilinear', warpMemoryLimit = 4000, multithread=True, srcSRS = \"EPSG:32617\", dstSRS = \"EPSG:4326\")\n",
    "    ds = gdal.Warp(\"outputs/conv.tiff\", ds, \n",
    "                   resampleAlg='bilinear', \n",
    "                   warpMemoryLimit = 4000, multithread=True,\n",
    "                   # outputBounds=[min(long1, long2), min(lat1, lat2), max(long1, long2), max(lat1, lat2)],\n",
    "                   srcSRS = \"EPSG:\" + str(src_srs),\n",
    "                   dstSRS = \"EPSG:4326\")\n",
    "    ds = None\n",
    "    min_x = min(long1, long2)\n",
    "    max_x = max(long1, long2)\n",
    "    min_y = min(lat1, lat2)\n",
    "    max_y = max(lat1, lat2)\n",
    "    ds = gdal.Open(\"outputs/conv.tiff\")\n",
    "    ds = gdal.Translate(output, ds, projWin = [min_x, max_y, max_x, min_y], resampleAlg='bilinear')\n",
    "    ds = None\n",
    "\n",
    "def crop_to_bb_utm(input, output, x1, y1, x2, y2):\n",
    "    ds = gdal.Open(input)\n",
    "    ## Keep some margin for cropping\n",
    "    min_x = min(x1, x2)  - 1000\n",
    "    max_x = max(x1, x2) + 1000\n",
    "    min_y = min(y1, y2) - 1000\n",
    "    max_y = max(y1, y2) + 1000\n",
    "    ds = gdal.Translate(output, ds, projWin = [min_x, max_y, max_x, min_y], resampleAlg='bilinear')\n",
    "    ds = None\n",
    "\n",
    "def get_utm_zone(latitude, longitude):\n",
    "    utm_info = utm.from_latlon(latitude, longitude)\n",
    "    return utm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5938e-73ab-4459-b174-05f3b1635c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bounding_box_area(min_lon, min_lat, max_lon, max_lat):\n",
    "    sw_point = (min_lat, min_lon)\n",
    "    ne_point = (max_lat, max_lon)\n",
    "    width = geodesic(sw_point, (max_lat, min_lon)).meters\n",
    "    height = geodesic(sw_point, (min_lat, max_lon)).meters\n",
    "    area = width * height\n",
    "    return area / (1000 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59c611-032b-497a-9843-7fc939ae8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_band_data(band, year, month, day, lat1, long1, lat2, long2, output_prefix):\n",
    "    b_files = download_tiles_for_band_with_composites(band, year, month, day, lat1, long1, lat2, long2)\n",
    "    output_files = []\n",
    "    p_f = []\n",
    "    r_f = []\n",
    "    a_f =[]\n",
    "    for i in range(len(b_files)):\n",
    "        output_files.append(output_prefix + str(i) + \".TIFF\")\n",
    "        downloaded_files, pixel_files, radsat_files, aerosol_files = b_files[i]\n",
    "        g = gdal.Warp(output_prefix + str(i) + \".TIFF\", \n",
    "                      downloaded_files, format=\"GTiff\", options=[\"COMPRESS=LZW\", \"TILED=YES\"], \n",
    "                      resampleAlg='bilinear') # if you want\n",
    "        g = None\n",
    "        p_f.append(output_prefix + str(i) + \"P.TIFF\")\n",
    "        g = gdal.Warp(output_prefix + str(i) + \"P.TIFF\", \n",
    "                      pixel_files, format=\"GTiff\", options=[\"COMPRESS=LZW\", \"TILED=YES\"], \n",
    "                      resampleAlg='bilinear', srcNodata= 1, dstNodata = 0) # if you want\n",
    "        g = None\n",
    "        r_f.append(output_prefix + str(i) + \"R.TIFF\")\n",
    "        g = gdal.Warp(output_prefix + str(i) + \"R.TIFF\", \n",
    "                      radsat_files, format=\"GTiff\", options=[\"COMPRESS=LZW\", \"TILED=YES\"], \n",
    "                      resampleAlg='bilinear', srcNodata= 1, dstNodata = 0) # if you want\n",
    "        g = None\n",
    "        a_f.append(output_prefix + str(i) + \"A.TIFF\")\n",
    "        g = gdal.Warp(output_prefix + str(i) + \"A.TIFF\", \n",
    "                      aerosol_files, format=\"GTiff\", options=[\"COMPRESS=LZW\", \"TILED=YES\"], \n",
    "                      resampleAlg='bilinear', srcNodata= 1, dstNodata = 0) # if you want\n",
    "        g = None\n",
    "    return output_files, p_f, r_f, a_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a61f52-53fd-4f30-b11b-e0e1b0d907a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gaps(pxs):\n",
    "    max_shape = np.max([matrix.shape for matrix in pxs], axis=0)\n",
    "    unified_matrices = np.zeros((len(pxs), *max_shape), dtype=np.float64)\n",
    "    for idx, matrix in enumerate(pxs):\n",
    "        unified_matrices[idx, :matrix.shape[0], :matrix.shape[1]] = matrix\n",
    "    return unified_matrices\n",
    "\n",
    "def check_values(values_to_check, array):\n",
    "    return (~np.isin(values_to_check, array)).astype(float)\n",
    "    \n",
    "def mark_cloud2(p_px):\n",
    "    cloud_px_values = [55052, 54852, 54596, 22280]\n",
    "    #cloud_px_values = [1, 54596, 54852, 55052, 24088, 24216, 24344, 24472, 23888, 23952, 22280, 21826, 21890]\n",
    "    return check_values(p_px, cloud_px_values)\n",
    "\n",
    "def mark_cloud(p_px):\n",
    "    #cloud_px_values = [55052, 54852, 54596, 22280]\n",
    "    #cloud_px_values = [1, 54596, 54852, 55052, 24088, 24216, 24344, 24472, 23888, 23952, 22280, 21826, 21890]\n",
    "    #cloud_px_values = list(range(1, 21823)) + list(range(21825, 65535))\n",
    "    cloud_px_values = list(range(1, 21823)) + list(range(21825, 21951)) + list(range(21953, 65535)) #keep 21824 and 21952 (clear land and clear water)\n",
    "    return check_values(p_px, cloud_px_values)\n",
    "\n",
    "def mark_aerosol2(a_px):\n",
    "    aerosol_px_values = [192, 194, 196, 224, 228]\n",
    "    return check_values(a_px, aerosol_px_values)\n",
    "\n",
    "def mark_aerosol(a_px):\n",
    "    aerosol_px_values = [192, 194, 196, 228]\n",
    "    return check_values(a_px, aerosol_px_values)\n",
    "\n",
    "def mark_radsat(r_px):\n",
    "    b3_r_px = check_values(r_px & 4, [4])\n",
    "    b4_r_px = check_values(r_px & 8, [8])\n",
    "    b5_r_px = check_values(r_px & 16, [16])\n",
    "    return b3_r_px, b4_r_px, b5_r_px\n",
    "\n",
    "def rescale_bands(band_data):\n",
    "    return band_data * 0.0000275 -0.2\n",
    "    \n",
    "def prepare_refernce_images(long1, lat1, long2, lat2):\n",
    "    ndvi_reference = 'NDVI/finalNDVI_Daniel_Large.tif'\n",
    "    min_x = min(long1, long2)\n",
    "    max_x = max(long1, long2)\n",
    "    min_y = min(lat1, lat2)\n",
    "    max_y = max(lat1, lat2)\n",
    "    ds = gdal.Open(ndvi_reference)\n",
    "    ds = gdal.Translate(\"outputs/ndvi_reference.tiff\", ds, projWin = [min_x, max_y, max_x, min_y], resampleAlg='bilinear')\n",
    "    ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ede45-7df2-41a0-a63d-ae11b26d2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lat1,long1,lat2,long2 =  get_peurto_coord()\n",
    "\n",
    "#lat1,long1,lat2,long2 = turkey()\n",
    "\n",
    "lat1,long1,lat2,long2 =  get_test_coord()\n",
    "year = 2023\n",
    "month = 1\n",
    "day = 24\n",
    "\n",
    "#x1 = 526070.974\n",
    "#y1 = 3655166.432\n",
    "#x2 = 680429.765\n",
    "#y2 = 3593707.569\n",
    "\n",
    "\n",
    "# (33.034682, 21.279194, 32.465949, 22.919832)\n",
    "x1, y1, _, _ = get_utm_zone(lat1,long1)\n",
    "x2, y2, _, _ = get_utm_zone(lat2,long2)\n",
    "\n",
    "#year = 2023\n",
    "#month = 1\n",
    "#day = 7\n",
    "\n",
    "\n",
    "#year = 2004\n",
    "#month = 12\n",
    "#day = 28\n",
    "\n",
    "#lat1,long1,lat2,long2 = get_fort_myers()\n",
    "#year = 2022\n",
    "#month = 5\n",
    "#day = 6\n",
    "\n",
    "# Example usage:\n",
    "min_lon = min(long1, long2)\n",
    "min_lat = min(lat1, lat2)\n",
    "max_lon = max(long1, long2)\n",
    "max_lat = max(lat1, lat2)\n",
    "\n",
    "bbox_area = calculate_bounding_box_area(min_lon, min_lat, max_lon, max_lat)\n",
    "print(f\"Area of the bounding box is approximately {bbox_area:.2f} square meters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ad894-69f6-4ae3-8db0-e36fc4833e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52205ee7-1010-4697-8305-d367916315df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecade33-6c0c-4c28-99d6-b43b4562d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_path = \"outputs/B3_Merged_\"\n",
    "b4_path = \"outputs/B4_Merged_\"\n",
    "b5_path = \"outputs/B5_Merged_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb56d00-e70c-48f8-9dc9-c9fdd1f02d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_outputs, b3_p, b3_r, b3_a = process_band_data(3, year, month, day, lat1, long1, lat2, long2, b3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759f24cd-7b16-4000-8423-7a7ee223021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_outputs, b4_p, b4_r, b4_a = process_band_data(4, year, month, day, lat1, long1, lat2, long2, b4_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb1013-8d44-475f-93a6-06c8701b89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b5_outputs, b5_p, b5_r, b5_a = process_band_data(5, year, month, day, lat1, long1, lat2, long2, b5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f98e1-eb25-4ad7-bf72-6822b9ce8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_final = []\n",
    "b4_final = []\n",
    "b5_final = []\n",
    "p_final = []\n",
    "r_final = []\n",
    "a_final = []\n",
    "\n",
    "for i in range(len(b3_outputs)):\n",
    "    crop_to_bb_utm(b3_outputs[i], 'outputs/B3_' + str(i) + '.TIFF', x1, y1, x2, y2)\n",
    "    b3_final.append('outputs/B3_' + str(i) + '.TIFF')\n",
    "    \n",
    "for i in range(len(b4_outputs)):\n",
    "    crop_to_bb_utm(b4_outputs[i], 'outputs/B4_' + str(i) + '.TIFF', x1, y1, x2, y2)\n",
    "    b4_final.append('outputs/B4_' + str(i) + '.TIFF')\n",
    "\n",
    "for i in range(len(b5_outputs)):\n",
    "    crop_to_bb_utm(b5_outputs[i], 'outputs/B5_' + str(i) + '.TIFF', x1, y1, x2, y2)\n",
    "    b5_final.append('outputs/B5_' + str(i) + '.TIFF')\n",
    "\n",
    "for i in range(len(b3_p)):\n",
    "    crop_to_bb_utm(b3_p[i], 'outputs/P_' + str(i) + '.TIFF', x1, y1, x2, y2)\n",
    "    p_final.append('outputs/P_' + str(i) + '.TIFF')\n",
    "\n",
    "for i in range(len(b3_r)):\n",
    "    crop_to_bb_utm(b3_r[i], 'outputs/R_' + str(i) + '.TIFF', x1, y1, x2, y2)\n",
    "    r_final.append('outputs/R_' + str(i) + '.TIFF')\n",
    "\n",
    "for i in range(len(b3_a)):\n",
    "    crop_to_bb_utm(b3_a[i], 'outputs/A_' + str(i) + '.TIFF', x1, y1, x2, y2)\n",
    "    a_final.append('outputs/A_' + str(i) + '.TIFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c0d39-d310-4ba0-ba61-d70882958e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_pxs = []\n",
    "b4_pxs = []\n",
    "b5_pxs = []\n",
    "for i in range(len(b3_final)):\n",
    "    p_px, in_geo, projref  = get_geo(p_final[i], 1)\n",
    "    a_px, in_geo, projref  = get_geo(a_final[i], 1)\n",
    "    r_px, in_geo, projref  = get_geo(r_final[i], 1)\n",
    "    cloud_pixels = mark_cloud(p_px)\n",
    "    aerosol_pixels = mark_aerosol(a_px)\n",
    "    b3_r_px, b4_r_px, b5_r_px = mark_radsat(r_px)\n",
    "    b3_px, in_geo, projref  = get_geo(b3_final[i], 1)\n",
    "    b4_px, in_geo, projref  = get_geo(b4_final[i], 1)\n",
    "    b5_px, in_geo, projref  = get_geo(b5_final[i], 1)\n",
    "    b3_px = b3_px  * cloud_pixels * aerosol_pixels * b3_r_px\n",
    "    b4_px = b4_px  * cloud_pixels * aerosol_pixels * b4_r_px\n",
    "    b5_px = b5_px  * cloud_pixels * aerosol_pixels * b5_r_px\n",
    "    b3_pxs.append(np.array(b3_px))\n",
    "    b4_pxs.append(np.array(b4_px))\n",
    "    b5_pxs.append(np.array(b5_px))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aad672-2833-4cbf-b96b-21f573c31abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3 = np.nanmedian(np.where(np.stack(b3_pxs) == 0, np.nan, np.stack(b3_pxs)), axis=0)\n",
    "b4 = np.nanmedian(np.where(np.stack(b4_pxs) == 0, np.nan, np.stack(b4_pxs)), axis=0)\n",
    "b5 = np.nanmedian(np.where(np.stack(b5_pxs) == 0, np.nan, np.stack(b5_pxs)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910e320-4348-4ee7-a0d5-f4912b665b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_geotiff_single(\"outputs/B3.TIFF\", b3, projref, in_geo)\n",
    "save_geotiff_single(\"outputs/B4.TIFF\", b4, projref, in_geo)\n",
    "save_geotiff_single(\"outputs/B5.TIFF\", b5, projref, in_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df5d65-364d-492d-9461-1f0b0bb10601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to\n",
    "convert_to_wgs84(\"outputs/B3.TIFF\", \"outputs/B3_WGS84.TIFF\", long1, lat1, long2, lat2)\n",
    "convert_to_wgs84(\"outputs/B4.TIFF\", \"outputs/B4_WGS84.TIFF\", long1, lat1, long2, lat2)\n",
    "convert_to_wgs84(\"outputs/B5.TIFF\", \"outputs/B5_WGS84.TIFF\", long1, lat1, long2, lat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656779bf-3f2a-49be-b5fb-35b7d62a68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download night images\n",
    "\n",
    "download_file = \"VNP46A2.h5\"\n",
    "\n",
    "vnp46Util = VNP46A2Util()\n",
    "vertical, horizontal = vnp46Util.coordinates_to_tile_id(lat1, long1)\n",
    "vnp46Util.download_h5(earthdata_token, year, month, day, vertical, horizontal, download_file)\n",
    "vnp46Util.convert_VNP46A2_HDF2TIFF(download_file, \"dnb_brdf_corrected_ntl.tif\", 0)\n",
    "vnp46Util.convert_VNP46A2_HDF2TIFF(download_file, \"dnb_lunar_irradiance.tif\", 1)\n",
    "vnp46Util.convert_VNP46A2_HDF2TIFF(download_file, \"gap_filled_dnb_brdf_corrected_ntl.tif\", 2)\n",
    "vnp46Util.convert_VNP46A2_HDF2TIFF(download_file, \"latest_high_quality_retrieval.tif\", 3)\n",
    "vnp46Util.convert_VNP46A2_HDF2TIFF(download_file, \"mandatory_quality_flag.tif\", 4)\n",
    "vnp46Util.convert_VNP46A2_HDF2TIFF(download_file, \"qf_cloud_mask.tif\", 5)\n",
    "vnp46Util.convert_VNP46A2_HDF2TIFF(download_file, \"snow_flag.tif\", 6)\n",
    "\n",
    "\n",
    "maxY = max(lat1, lat2)\n",
    "minY = min(lat1, lat2)\n",
    "maxX = max(long1, long2)\n",
    "minX = min(long1, long2)\n",
    "scale = 0.00011111111\n",
    "#scale = 0.00025\n",
    "\n",
    "subset_raster_normal(\"dnb_brdf_corrected_ntl.tif\", \"outputs/dnb_brdf_corrected_ntl.tif\", minX, maxY, maxX, minY, scale) \n",
    "subset_raster_normal(\"dnb_lunar_irradiance.tif\", \"outputs/dnb_lunar_irradiance.tif\", minX, maxY, maxX, minY, scale) \n",
    "subset_raster_normal(\"gap_filled_dnb_brdf_corrected_ntl.tif\", \"outputs/gap_filled_dnb_brdf_corrected_ntl.tif\", minX, maxY, maxX, minY, scale) \n",
    "subset_raster_normal(\"latest_high_quality_retrieval.tif\", \"outputs/latest_high_quality_retrieval.tif\", minX, maxY, maxX, minY, scale) \n",
    "subset_raster_normal(\"mandatory_quality_flag.tif\", \"outputs/mandatory_quality_flag.tif\", minX, maxY, maxX, minY, scale) \n",
    "subset_raster_normal(\"qf_cloud_mask.tif\", \"outputs/qf_cloud_mask.tif\", minX, maxY, maxX, minY, scale) \n",
    "subset_raster_normal(\"snow_flag.tif\", \"outputs/snow_flag.tif\", minX, maxY, maxX, minY, scale) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa682c61-d602-4a44-919d-ae7c74881569",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntl, in_geo, projref  = get_geo(\"outputs/gap_filled_dnb_brdf_corrected_ntl.tif\", 1)\n",
    "lunar_irradiance, in_geo, projref  = get_geo(\"outputs/dnb_lunar_irradiance.tif\", 1)\n",
    "mandatory_quality_flag, in_geo, projref  = get_geo(\"outputs/mandatory_quality_flag.tif\", 1)\n",
    "gap_filled_ntl, in_geo, projref  = get_geo(\"outputs/gap_filled_dnb_brdf_corrected_ntl.tif\", 1)\n",
    "\n",
    "\n",
    "img_ntl =  np.where(gap_filled_ntl > 65534, 0, gap_filled_ntl) # * 0.1 # scale factor\n",
    "\n",
    "#img_lunar_irradiance =  np.where(lunar_irradiance != 5, 0, lunar_irradiance)\n",
    "#img_lunar_irradiance = img_lunar_irradiance / 5\n",
    "adjusted_ntl = img_ntl # * img_lunar_irradiance # * (mandatory_quality_flag <= 3).astype(float)\n",
    "#adjusted_ntl = img_ntl * ((mandatory_quality_flag <= 3)).astype(float) # - img_lunar_irradiance\n",
    "save_geotiff_single(\"outputs/adjusted_ntl.TIFF\", adjusted_ntl, projref, in_geo)\n",
    "save_geotiff_single(\"outputs/img_ntl.TIFF\", img_ntl, projref, in_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c702a4-7159-4779-b5ed-1ecccb0fd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download openstreet maps\n",
    "osm_utl = OSMUtil()\n",
    "osm_utl.create_road_raster(lat1, long1, lat2, long2,  output_path=\"outputs/osm.tif\", \n",
    "                           raster_value = 1, path_thickness = 0.00005, reference_raster = \"outputs/adjusted_ntl.TIFF\")\n",
    "#osm_utl.create_road_raster_flattened(lat1, long1, lat2, long2,  output_path=\"outputs/osm.tif\", raster_value = 1, path_thickness = 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec6516-ccda-4f45-9dea-c3e06139c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_refernce_images(long1, lat1, long2, lat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410db3c2-1848-402b-ba5e-038c63d3e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_files = ['outputs/B3_WGS84.TIFF', 'outputs/B4_WGS84.TIFF', 'outputs/B5_WGS84.TIFF',\n",
    "               'outputs/adjusted_ntl.TIFF', 'outputs/osm.tif', 'outputs/ndvi_reference.tiff']  # Add your file names\n",
    "\n",
    "# Output file names\n",
    "output_files = ['outputs/final/B3.TIFF', 'outputs/final/B4.TIFF', \n",
    "                'outputs/final/B5.TIFF', \n",
    "                'outputs/final/ntl.tif', 'outputs/final/osm.tif', \n",
    "                'outputs/final/ndvi_reference.tiff']  # Output names corresponding to input\n",
    "\n",
    "# Desired resolution\n",
    "desired_resolution = (0.0001, -0.0001)  # Replace with your desired resolution in degrees (x_resolution, y_resolution)\n",
    "\n",
    "# Loop through each input file\n",
    "for i, input_file in enumerate(input_files):\n",
    "    output_file = output_files[i]\n",
    "    # Open the input dataset\n",
    "    input_dataset = gdal.Open(input_file)\n",
    "    # Perform the resampling to the desired resolution\n",
    "    gdal.Warp(output_file, input_dataset, format='GTiff', xRes=desired_resolution[0], yRes=desired_resolution[1])\n",
    "    # Close the input dataset\n",
    "    input_dataset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246249fb-e492-4e2f-a1cf-5b18aa33385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_final_px, in_geo, projref = get_geo('outputs/final/B3.TIFF', 1)\n",
    "b4_final_px, _, _ = get_geo('outputs/final/B4.TIFF', 1)\n",
    "b5_final_px, _, _ = get_geo('outputs/final/B5.TIFF', 1)\n",
    "osm_final_px, _, _ = get_geo('outputs/final/osm.tif', 1)\n",
    "ntl_final_px, _, _ = get_geo('outputs/final/ntl.tif', 1)\n",
    "\n",
    "gaps_filed_stack = fill_gaps([b3_final_px, b4_final_px, b5_final_px, osm_final_px, ntl_final_px])\n",
    "\n",
    "b3_final_px = rescale_bands(gaps_filed_stack[0])\n",
    "b4_final_px = rescale_bands(gaps_filed_stack[1])\n",
    "b5_final_px = rescale_bands(gaps_filed_stack[2])\n",
    "osm_final_px = gaps_filed_stack[3]\n",
    "ntl_final_px = gaps_filed_stack[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e0fc2-6cda-4530-91f6-6c7af75f211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = (b5_final_px - b4_final_px) / (b5_final_px + b4_final_px)\n",
    "ndwi = (b3_final_px - b5_final_px) / (b3_final_px + b5_final_px)\n",
    "\n",
    "ndvi = np.where(ndvi > 1, 1.0, ndvi)\n",
    "ndvi = np.where(ndvi < -1, -1.0, ndvi)\n",
    "\n",
    "ndwi = np.where(ndwi > 1, 1.0, ndwi)\n",
    "ndwi = np.where(ndwi < -1, -1.0, ndwi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b92801-24f2-49d3-b3e9-1ba4ca2383ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntl_floor = 0.1\n",
    "ntl_ceiling = 10\n",
    "ndui_floor = 0.02\n",
    "\n",
    "##############Read Images as Array################\n",
    "img_road = osm_final_px\n",
    "img_ndvi = ndvi\n",
    "img_ndwi = ndwi\n",
    "img_ntl = ntl_final_px\n",
    "\n",
    "#make nodate (65535) as zero\n",
    "img_ntl =  np.where(img_ntl > 65534, 0, img_ntl)\n",
    "\n",
    "#Scale Radiance value If needed\n",
    "img_ntl = img_ntl.astype(float)\n",
    "img_ntl = img_ntl/10\n",
    "\n",
    "###############Calculate NDUI#############################\n",
    "img_ntl = np.where(img_ntl > ntl_ceiling, ntl_ceiling, img_ntl)\n",
    "img_ntl = np.where(img_ntl < ntl_floor, 0.0, img_ntl)\n",
    "img_ntl = img_ntl/ntl_ceiling\n",
    "\n",
    "ndui = (((img_ntl - img_ndvi))/((img_ntl + img_ndvi + 0.00001)))\n",
    "\n",
    "ndui = np.where(ndui > 1.0, 1.0, ndui)\n",
    "ndui = np.where(ndui < -1.0, -1.0, ndui)\n",
    "\n",
    "#Apply Water Mask\n",
    "ndui = np.where(img_ndwi >= 0.0, -1.0, ndui)\n",
    "\n",
    "ndui  = abs((ndui+1.0))/2.0\n",
    "ndui = np.where(ndui < ndui_floor, 0.0, ndui)\n",
    "\n",
    "#increase intensity for roads\n",
    "ndui = np.where((img_road == 1)|(img_road == 4), ndui*1.3, ndui)\n",
    "ndui = np.where((img_road == 2)|(img_road == 3)|(img_road == 5)|(img_road == 6), ndui*1.1, ndui)\n",
    "\n",
    "ndui = ndui / 1.3\n",
    "\n",
    "output_co = \"outputs/final/ndui-co.tif\"\n",
    "\n",
    "#### Output Image Scale Range from 0 to 1 (Best display value 0.3 - 0.8)##############\n",
    "min_value = 0.3\n",
    "max_value = 0.8\n",
    "\n",
    "r = np.load('inferno_r.npy')\n",
    "g = np.load('inferno_g.npy')\n",
    "b = np.load('inferno_b.npy')\n",
    "\n",
    "r[0] = 0\n",
    "g[0] = 0\n",
    "b[0] = 0\n",
    "\n",
    "img_ndui_scale = scale_image(ndui, min_value, max_value)\n",
    "\n",
    "post_rr = r[img_ndui_scale]\n",
    "post_gg = g[img_ndui_scale]\n",
    "post_bb = b[img_ndui_scale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b8732-830b-4ce1-a218-cf911908aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('outputs/final/B3.TIFF') as src: # Get metadata information from a processed B3\n",
    "        arr = src.read()\n",
    "        kwargs = src.meta\n",
    "    \n",
    "kwargs['dtype'] = 'uint8'\n",
    "kwargs['count'] = 3\n",
    "arr = np.array([post_rr, post_gg, post_bb]).astype(np.uint8)\n",
    "\n",
    "kwargs.update(driver=\"GTiff\", predictor=2)\n",
    "with MemoryFile() as memfile:\n",
    "    # Opening an empty MemoryFile for in memory operation - faster\n",
    "    with memfile.open(**kwargs) as mem:\n",
    "        # Writing the array values to MemoryFile using the rasterio.io module\n",
    "        # https://rasterio.readthedocs.io/en/stable/api/rasterio.io.html\n",
    "        mem.write(arr)\n",
    "\n",
    "        dst_profile = cog_profiles.get(\"deflate\")\n",
    "\n",
    "        # Creating destination COG\n",
    "        cog_translate(\n",
    "            mem,\n",
    "            output_co,\n",
    "            dst_profile,\n",
    "            in_memory=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05589bb4-2332-4f4a-8daf-ff339b1fdb3c",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10762dd-6219-42ee-ad0f-5bed87db2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "\n",
    "ndvi_target, _, _ = get_geo('outputs/final/ndvi_reference.tiff', 1)\n",
    "#new_ndvi = np.where(ndvi < 0, 0, ndvi)\n",
    "new_ndvi = ndvi\n",
    "\n",
    "shape1 = ndvi.shape\n",
    "shape2 = ndvi_target.shape\n",
    "\n",
    "# Determine the maximum dimensions\n",
    "max_width = max(shape1[1], shape2[1])\n",
    "max_height = max(shape1[0], shape2[0])\n",
    "\n",
    "# Resize images to match the maximum dimensions\n",
    "resized_img1 = resize(new_ndvi, (max_height, max_width), anti_aliasing=True)\n",
    "resized_img2 = resize(ndvi_target, (max_height, max_width), anti_aliasing=True)\n",
    "\n",
    "# Display the resized images side by side\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 6))  # Create subplots for two images\n",
    "im1 = axes[0].imshow(resized_img1,vmin=-1, vmax=1, cmap='jet', aspect='auto')\n",
    "axes[0].set_title('Generated')\n",
    "fig.colorbar(im1, orientation='vertical')\n",
    "#axes[0].axis('off')\n",
    "\n",
    "im2 = axes[1].imshow(resized_img2,vmin=-1, vmax=1, cmap='jet', aspect='auto')\n",
    "axes[1].set_title('Reference')\n",
    "fig.colorbar(im2, orientation='vertical')\n",
    "#axes[1].axis('off')\n",
    "\n",
    "im3 = axes[2].imshow(resized_img2 - resized_img1,vmin=-0.2, vmax=0.2, cmap='jet', aspect='auto')\n",
    "axes[2].set_title('Diff = Reference - Generated')\n",
    "fig.colorbar(im3, orientation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0da05b-c26b-4de1-a0a8-8c305de35868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Paths to your image files\n",
    "image_paths = ['outputs/final/ndui.tif', 'finalBMHD_VNP46A2_Daniel_2023249.tif']  # Replace these with your image paths\n",
    "\n",
    "# Create subplots for displaying images side by side\n",
    "fig, axes = plt.subplots(1, len(image_paths), figsize=(15, 5))  # Adjust figsize as needed\n",
    "\n",
    "# Load and display images in the subplots\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    img = mpimg.imread(img_path)  # Load the image using Matplotlib\n",
    "    axes[i].imshow(img)  # Display the image in the corresponding subplot\n",
    "    axes[i].axis('off')  # Hide axes\n",
    "\n",
    "# Show the subplots\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08949480-7259-4bd5-b63e-eaee2b69994d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
